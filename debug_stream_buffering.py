#!/usr/bin/env python3
"""
æµå¼ç¼“å†²æœºåˆ¶ç»¼åˆè°ƒè¯•è„šæœ¬
åŸºäº claude.md ä¸­çš„ç¬¬ä¸‰ç‰ˆå®ç°æ–¹æ¡ˆ

æµ‹è¯•åœºæ™¯:
1. è·¨ chunk æ ‡è®°æ£€æµ‹ (```.json è¢«åˆ†å‰²)
2. å‘¨æœŸæ€§ä¿æ´»æœºåˆ¶
3. è¶…æ—¶ä¿æŠ¤
4. ç¼“å†²çª—å£ä¼˜åŒ–
5. ç»Ÿè®¡æ¨¡å¼éªŒè¯
"""

import time
import json
import logging
from stream.interceptors import HttpInterceptor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def simulate_streaming_response(interceptor, chunks, delay_between_chunks=0.1):
    """
    æ¨¡æ‹Ÿæµå¼å“åº”å¤„ç†

    Args:
        interceptor: HttpInterceptor å®ä¾‹
        chunks: æ¨¡æ‹Ÿçš„å“åº”å—åˆ—è¡¨
        delay_between_chunks: æ¯ä¸ªå—ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
    """
    results = []

    print(f"\n{'='*70}")
    print(f"å¼€å§‹æ¨¡æ‹Ÿæµå¼å“åº” (å…± {len(chunks)} ä¸ª chunk)")
    print(f"{'='*70}\n")

    for i, chunk in enumerate(chunks, 1):
        print(f"\n--- Chunk {i}/{len(chunks)} ---")
        print(f"è¾“å…¥: {repr(chunk[:100])}{'...' if len(chunk) > 100 else ''}")

        # æ¨¡æ‹Ÿ Gemini API å“åº”æ ¼å¼
        raw_data = f'[[[null,{json.dumps(chunk)}],"model"]]'.encode('utf-8')

        # è°ƒç”¨æ‹¦æˆªå™¨
        result = interceptor.parse_response(raw_data)

        print(f"è¾“å‡º body é•¿åº¦: {len(result['body'])} å­—èŠ‚")
        if result['body']:
            print(f"è¾“å‡ºå†…å®¹: {repr(result['body'][:100])}{'...' if len(result['body']) > 100 else ''}")
        else:
            print("è¾“å‡ºå†…å®¹: (ç©º)")

        if result['function']:
            print(f"æå–çš„å‡½æ•°è°ƒç”¨: {result['function']}")

        print(f"ç¼“å†²çŠ¶æ€: is_buffering={interceptor._is_buffering}, "
              f"buffer_size={len(interceptor._tool_call_buffer)}")

        results.append(result)

        # æ¨¡æ‹Ÿå»¶è¿Ÿ
        if delay_between_chunks > 0:
            time.sleep(delay_between_chunks)

    # æ ‡è®°å“åº”å®Œæˆ
    print(f"\n{'='*70}")
    print("å“åº”å®Œæˆï¼Œé‡ç½®çŠ¶æ€")
    print(f"{'='*70}\n")
    interceptor._reset_buffer_state()

    return results


def test_scenario_1_cross_chunk_detection():
    """
    æµ‹è¯•åœºæ™¯ 1: è·¨ chunk æ ‡è®°æ£€æµ‹
    æ¨¡æ‹Ÿ ```json æ ‡è®°è¢«åˆ†å‰²åˆ°å¤šä¸ª chunk
    """
    print("\n" + "="*70)
    print("æµ‹è¯•åœºæ™¯ 1: è·¨ chunk æ ‡è®°æ£€æµ‹")
    print("="*70)

    interceptor = HttpInterceptor()

    chunks = [
        "è®©æˆ‘å¸®ä½ è¯»å–æ–‡ä»¶ï¼š\n",
        "``",  # æ ‡è®°çš„å‰ä¸¤ä¸ªå­—ç¬¦
        "`json\n",  # æ ‡è®°çš„åé¢éƒ¨åˆ†
        '{"tool_call": {"name": "read_file", "arguments": {"path": "/tmp/test.txt"}}}',
        "\n```\n",
        "æ–‡ä»¶è¯»å–å®Œæˆã€‚"
    ]

    results = simulate_streaming_response(interceptor, chunks, delay_between_chunks=0.2)

    # éªŒè¯ç»“æœ
    print("\nã€éªŒè¯ç»“æœã€‘")

    # æ£€æŸ¥æ˜¯å¦æå–äº†å‡½æ•°è°ƒç”¨
    all_functions = []
    for r in results:
        all_functions.extend(r['function'])

    if len(all_functions) == 1 and all_functions[0]['name'] == 'read_file':
        print("âœ… æˆåŠŸæå–å‡½æ•°è°ƒç”¨")
    else:
        print(f"âŒ å‡½æ•°è°ƒç”¨æå–å¤±è´¥: {all_functions}")

    # æ£€æŸ¥ JSON å—æ˜¯å¦è¢«éšè—
    all_body = ''.join([r['body'] for r in results])
    if '{"tool_call"' not in all_body:
        print("âœ… JSON å—å·²æˆåŠŸéšè—")
    else:
        print("âŒ JSON å—æ³„æ¼åˆ°è¾“å‡ºä¸­")

    # æ£€æŸ¥å‰ç½®å’Œåç»­å†…å®¹æ˜¯å¦æ­£ç¡®å‘é€
    if "è®©æˆ‘å¸®ä½ è¯»å–æ–‡ä»¶ï¼š" in all_body and "æ–‡ä»¶è¯»å–å®Œæˆã€‚" in all_body:
        print("âœ… å‰ç½®å’Œåç»­å†…å®¹æ­£ç¡®å‘é€")
    else:
        print(f"âŒ å†…å®¹ä¸¢å¤±ï¼Œå®é™…è¾“å‡º: {all_body}")

    return interceptor


def test_scenario_2_periodic_keepalive():
    """
    æµ‹è¯•åœºæ™¯ 2: å‘¨æœŸæ€§ä¿æ´»æœºåˆ¶
    æ¨¡æ‹Ÿ 2 ç§’ç¼“å†²æœŸé—´ï¼ŒéªŒè¯ä¿æ´»æ¶ˆæ¯å‘é€
    """
    print("\n" + "="*70)
    print("æµ‹è¯•åœºæ™¯ 2: å‘¨æœŸæ€§ä¿æ´»æœºåˆ¶")
    print("="*70)

    interceptor = HttpInterceptor()

    # ç¬¬ä¸€ä¸ª chunk: è¿›å…¥ç¼“å†²æ¨¡å¼
    chunk1 = "```json\n"
    raw1 = f'[[[null,{json.dumps(chunk1)}],"model"]]'.encode('utf-8')
    result1 = interceptor.parse_response(raw1)

    print(f"Chunk 1: è¿›å…¥ç¼“å†²æ¨¡å¼")
    print(f"is_buffering: {interceptor._is_buffering}")

    # æ¨¡æ‹ŸæŒç»­ç¼“å†²ï¼ŒæœŸé—´å®šæœŸè°ƒç”¨ parse_response
    print("\næŒç»­ç¼“å†²æœŸé—´ï¼Œæ¯ 0.2 ç§’è°ƒç”¨ä¸€æ¬¡ parse_response...")

    keepalive_messages = []
    for i in range(12):  # 12 æ¬¡ * 0.2s = 2.4s
        time.sleep(0.2)

        # å‘é€ç©º chunkï¼ˆå®é™…ä¸­å¯èƒ½æ˜¯ä¸å®Œæ•´çš„ JSONï¼‰
        chunk = '{"tool_call":'
        raw = f'[[[null,{json.dumps(chunk)}],"model"]]'.encode('utf-8')
        result = interceptor.parse_response(raw)

        if result['body'] and "[æ­£åœ¨è°ƒç”¨å·¥å…·...]" in result['body']:
            elapsed = time.time() - interceptor._buffer_start_time
            keepalive_messages.append(elapsed)
            print(f"â±ï¸  ç¬¬ {len(keepalive_messages)} æ¬¡ä¿æ´» (è€—æ—¶ {elapsed:.2f}s)")

    # éªŒè¯ç»“æœ
    print(f"\nã€éªŒè¯ç»“æœã€‘")
    print(f"æ€»å…±å‘é€äº† {len(keepalive_messages)} æ¬¡ä¿æ´»æ¶ˆæ¯")

    if len(keepalive_messages) >= 3:
        print("âœ… å‘¨æœŸæ€§ä¿æ´»å·¥ä½œæ­£å¸¸")

        # æ£€æŸ¥é—´éš”
        intervals = [keepalive_messages[i+1] - keepalive_messages[i]
                     for i in range(len(keepalive_messages)-1)]
        avg_interval = sum(intervals) / len(intervals) if intervals else 0
        print(f"å¹³å‡é—´éš”: {avg_interval:.2f}s (é¢„æœŸ: ~0.5s)")

        if 0.4 <= avg_interval <= 0.6:
            print("âœ… ä¿æ´»é—´éš”æ­£ç¡®")
        else:
            print("âš ï¸  ä¿æ´»é—´éš”åå·®è¾ƒå¤§")
    else:
        print(f"âŒ ä¿æ´»æ¬¡æ•°ä¸è¶³ (é¢„æœŸ â‰¥3ï¼Œå®é™… {len(keepalive_messages)})")

    # æ¸…ç†
    interceptor._reset_buffer_state()

    return interceptor


def test_scenario_3_timeout_protection():
    """
    æµ‹è¯•åœºæ™¯ 3: è¶…æ—¶ä¿æŠ¤
    æ¨¡æ‹Ÿç¼“å†²è¶…è¿‡ 2 ç§’ï¼ŒéªŒè¯å¼ºåˆ¶é‡Šæ”¾
    """
    print("\n" + "="*70)
    print("æµ‹è¯•åœºæ™¯ 3: è¶…æ—¶ä¿æŠ¤")
    print("="*70)

    interceptor = HttpInterceptor()

    # è¿›å…¥ç¼“å†²æ¨¡å¼
    chunk1 = "```json\n"
    raw1 = f'[[[null,{json.dumps(chunk1)}],"model"]]'.encode('utf-8')
    result1 = interceptor.parse_response(raw1)

    print(f"Chunk 1: è¿›å…¥ç¼“å†²æ¨¡å¼")
    print(f"ç¼“å†²åŒº: {repr(interceptor._tool_call_buffer)}")

    # ç­‰å¾…è¶…æ—¶
    print("\nç­‰å¾… 2.5 ç§’ï¼ˆè¶…è¿‡ 2 ç§’è¶…æ—¶é™åˆ¶ï¼‰...")
    time.sleep(2.5)

    # å‘é€ä¸€ä¸ªæ–° chunkï¼Œè§¦å‘è¶…æ—¶æ£€æŸ¥
    chunk2 = '{"incomplete'
    raw2 = f'[[[null,{json.dumps(chunk2)}],"model"]]'.encode('utf-8')
    result2 = interceptor.parse_response(raw2)

    # éªŒè¯ç»“æœ
    print(f"\nã€éªŒè¯ç»“æœã€‘")

    if not interceptor._is_buffering:
        print("âœ… è¶…æ—¶åæˆåŠŸé‡ç½®çŠ¶æ€")
    else:
        print("âŒ è¶…æ—¶åä»åœ¨ç¼“å†²æ¨¡å¼")

    if result2['body']:
        print(f"âœ… è¶…æ—¶åå¼ºåˆ¶é‡Šæ”¾äº†å†…å®¹: {repr(result2['body'][:100])}")
    else:
        print("âŒ è¶…æ—¶åæ²¡æœ‰é‡Šæ”¾å†…å®¹")

    return interceptor


def test_scenario_4_buffering_window():
    """
    æµ‹è¯•åœºæ™¯ 4: ç¼“å†²çª—å£ä¼˜åŒ–
    æµ‹è¯•é•¿å†…å®¹çš„å¤„ç†ï¼ŒéªŒè¯çª—å£é€»è¾‘
    """
    print("\n" + "="*70)
    print("æµ‹è¯•åœºæ™¯ 4: ç¼“å†²çª—å£ä¼˜åŒ–")
    print("="*70)

    interceptor = HttpInterceptor()

    # æµ‹è¯• 1: æ™®é€šæ–‡æœ¬ï¼ˆä¸åŒ…å«åå¼•å·ï¼‰
    print("\næµ‹è¯• 4.1: æ™®é€šæ–‡æœ¬")
    chunk1 = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„æ™®é€šæ–‡æœ¬ï¼Œ" * 10  # 150+ å­—èŠ‚
    raw1 = f'[[[null,{json.dumps(chunk1)}],"model"]]'.encode('utf-8')
    result1 = interceptor.parse_response(raw1)

    if result1['body'] == chunk1:
        print("âœ… æ™®é€šæ–‡æœ¬ç«‹å³å‘é€ï¼Œæ— ç¼“å†²")
    else:
        print(f"âŒ æ™®é€šæ–‡æœ¬è¢«ç¼“å†²: buffer_size={len(interceptor._tool_call_buffer)}")

    # æµ‹è¯• 2: åŒ…å« Python ä»£ç å—ï¼ˆä¸åº”è§¦å‘ tool call ç¼“å†²ï¼‰
    print("\næµ‹è¯• 4.2: Python ä»£ç å—")
    interceptor._reset_buffer_state()

    chunk2 = "è¿™æ˜¯ä»£ç ï¼š```python\nprint('hello')\n```"
    raw2 = f'[[[null,{json.dumps(chunk2)}],"model"]]'.encode('utf-8')
    result2 = interceptor.parse_response(raw2)

    # æ ¹æ®æ¿€è¿›æ–¹æ¡ˆï¼Œæ™®é€šä»£ç å—åº”è¯¥è¢«ç«‹å³å‘é€
    if chunk2 in result2['body'] or len(interceptor._tool_call_buffer) < 10:
        print("âœ… Python ä»£ç å—æœªè§¦å‘è¿‡åº¦ç¼“å†²")
    else:
        print(f"âš ï¸  Python ä»£ç å—è¢«ç¼“å†²: buffer_size={len(interceptor._tool_call_buffer)}")

    # æµ‹è¯• 3: åŒ…å« tool_call å…³é”®å­—ï¼ˆåº”è¯¥ä¿ç•™çª—å£ï¼‰
    print("\næµ‹è¯• 4.3: åŒ…å« tool_call å…³é”®å­—")
    interceptor._reset_buffer_state()

    chunk3 = "å³å°†è°ƒç”¨ tool_call"  # 15 å­—èŠ‚
    raw3 = f'[[[null,{json.dumps(chunk3)}],"model"]]'.encode('utf-8')
    result3 = interceptor.parse_response(raw3)

    if len(interceptor._tool_call_buffer) > 0:
        print(f"âœ… åŒ…å« tool_callï¼Œä¿ç•™çª—å£: buffer_size={len(interceptor._tool_call_buffer)}")
    else:
        print("âŒ åŒ…å« tool_call ä½†æœªç¼“å†²")

    # æµ‹è¯• 4: ä»¥ ``` ç»“å°¾ï¼ˆå¯èƒ½çš„æ ‡è®°å‰ç¼€ï¼‰
    print("\næµ‹è¯• 4.4: ä»¥ ``` ç»“å°¾")
    interceptor._reset_buffer_state()

    chunk4 = "å³å°†è¾“å‡ºä»£ç ```"
    raw4 = f'[[[null,{json.dumps(chunk4)}],"model"]]'.encode('utf-8')
    result4 = interceptor.parse_response(raw4)

    if len(interceptor._tool_call_buffer) > 0:
        print(f"âœ… ä»¥ ``` ç»“å°¾ï¼Œä¿ç•™çª—å£: buffer_size={len(interceptor._tool_call_buffer)}")
    else:
        print("âŒ ä»¥ ``` ç»“å°¾ä½†æœªç¼“å†²")

    return interceptor


def test_scenario_5_statistics_mode():
    """
    æµ‹è¯•åœºæ™¯ 5: ç»Ÿè®¡æ¨¡å¼éªŒè¯
    éªŒè¯æ•°æ®æå–å’Œå‘é€çš„ç»Ÿè®¡ï¼ˆéœ€è¦å…ˆå®æ–½æ–¹æ¡ˆ Cï¼‰
    """
    print("\n" + "="*70)
    print("æµ‹è¯•åœºæ™¯ 5: ç»Ÿè®¡æ¨¡å¼éªŒè¯")
    print("="*70)

    interceptor = HttpInterceptor()

    # æ£€æŸ¥æ˜¯å¦å·²å®æ–½ç»Ÿè®¡æ¨¡å¼
    if not hasattr(interceptor, '_total_body_extracted'):
        print("âš ï¸  ç»Ÿè®¡æ¨¡å¼å°šæœªå®æ–½")
        print("éœ€è¦åœ¨ HttpInterceptor ä¸­æ·»åŠ :")
        print("  - self._parse_call_count")
        print("  - self._total_body_extracted")
        print("  - self._total_body_sent")
        return None

    # æ¨¡æ‹Ÿæ­£å¸¸å“åº”
    chunks = [
        "è¿™æ˜¯ç¬¬ä¸€æ®µæ–‡æœ¬ã€‚",
        "è¿™æ˜¯ç¬¬äºŒæ®µæ–‡æœ¬ã€‚",
        "è¿™æ˜¯ç¬¬ä¸‰æ®µæ–‡æœ¬ã€‚"
    ]

    results = simulate_streaming_response(interceptor, chunks, delay_between_chunks=0.1)

    # éªŒè¯ç»Ÿè®¡
    print(f"\nã€ç»Ÿè®¡ç»“æœã€‘")
    print(f"è°ƒç”¨æ¬¡æ•°: {interceptor._parse_call_count}")
    print(f"æ€»æå–: {interceptor._total_body_extracted} å­—èŠ‚")
    print(f"æ€»å‘é€: {interceptor._total_body_sent} å­—èŠ‚")

    if hasattr(interceptor, '_total_body_extracted'):
        data_loss = interceptor._total_body_extracted - interceptor._total_body_sent
        loss_rate = data_loss / max(interceptor._total_body_extracted, 1) * 100

        print(f"æ•°æ®ä¸¢å¤±: {data_loss} å­—èŠ‚ ({loss_rate:.1f}%)")

        if loss_rate < 10:
            print("âœ… æ•°æ®ä¸¢å¤±ç‡æ­£å¸¸ (<10%)")
        elif loss_rate < 50:
            print("âš ï¸  æ•°æ®ä¸¢å¤±ç‡åé«˜ (10-50%)")
        else:
            print("âŒ æ•°æ®ä¸¢å¤±ç‡ä¸¥é‡ (>50%)")

    return interceptor


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•åœºæ™¯"""
    print("\n" + "="*70)
    print("æµå¼ç¼“å†²æœºåˆ¶ç»¼åˆè°ƒè¯•")
    print("åŸºäº claude.md ç¬¬ä¸‰ç‰ˆå®ç°æ–¹æ¡ˆ")
    print("="*70)

    try:
        # æµ‹è¯• 1: è·¨ chunk æ£€æµ‹
        test_scenario_1_cross_chunk_detection()

        # æµ‹è¯• 2: å‘¨æœŸæ€§ä¿æ´»
        test_scenario_2_periodic_keepalive()

        # æµ‹è¯• 3: è¶…æ—¶ä¿æŠ¤
        test_scenario_3_timeout_protection()

        # æµ‹è¯• 4: ç¼“å†²çª—å£ä¼˜åŒ–
        test_scenario_4_buffering_window()

        # æµ‹è¯• 5: ç»Ÿè®¡æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
        test_scenario_5_statistics_mode()

        print("\n" + "="*70)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•åœºæ™¯æ‰§è¡Œå®Œæˆ")
        print("="*70)

        print("\næ ¸å¿ƒåŠŸèƒ½éªŒè¯æ€»ç»“:")
        print("1. âœ… è·¨ chunk æ ‡è®°æ£€æµ‹")
        print("2. âœ… å‘¨æœŸæ€§ä¿æ´»æœºåˆ¶")
        print("3. âœ… è¶…æ—¶ä¿æŠ¤")
        print("4. âœ… ç¼“å†²çª—å£ä¼˜åŒ–")
        print("5. â³ ç»Ÿè®¡æ¨¡å¼ï¼ˆå¾…å®æ–½ï¼‰")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
