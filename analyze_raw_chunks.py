#!/usr/bin/env python3
"""
Gemini åŸå§‹å“åº”å®Œæ•´åˆ†æå·¥å…·

ä» debug_output/gemini_raw_chunks.jsonl è¯»å–å®Œæ•´çš„åŸå§‹æ•°æ®å¹¶è¿›è¡Œæ·±åº¦åˆ†æ
"""

import json
from pathlib import Path
from datetime import datetime


def analyze_raw_chunks():
    print("=" * 80)
    print("ğŸ” Gemini åŸå§‹å“åº”å®Œæ•´åˆ†æ")
    print("=" * 80)
    print()

    chunks_file = Path('debug_output/gemini_raw_chunks.jsonl')

    if not chunks_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {chunks_file}")
        print()
        print("è¯·ç¡®è®¤ï¼š")
        print("  1. æœåŠ¡å·²å¯åŠ¨å¹¶ä¿®æ”¹äº† interceptors.py")
        print("  2. è‡³å°‘è§¦å‘è¿‡ä¸€æ¬¡è¯·æ±‚")
        print()
        return

    # è¯»å–æ‰€æœ‰ chunk
    chunks = []
    with open(chunks_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    chunk = json.loads(line)
                    chunks.append(chunk)
                except Exception as e:
                    print(f"âš ï¸  è§£æè¡Œå¤±è´¥: {e}")

    if not chunks:
        print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½• chunk æ•°æ®")
        return

    print(f"âœ… æ‰¾åˆ° {len(chunks)} ä¸ªåŸå§‹å“åº” chunk")
    print()

    # åˆ›å»ºè¯¦ç»†åˆ†ææ–‡ä»¶
    output_dir = Path('debug_output')
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = output_dir / f'gemini_complete_analysis_{timestamp}.txt'

    total_bytes = 0
    total_content_chars = 0
    all_contents = []

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("Gemini API åŸå§‹å“åº”å®Œæ•´åˆ†æ\n")
        f.write(f"åˆ†ææ—¶é—´: {datetime.now()}\n")
        f.write(f"æ€» Chunk æ•°: {len(chunks)}\n")
        f.write("=" * 80 + "\n\n")

        for chunk in chunks:
            chunk_num = chunk['chunk_num']
            data_hex = chunk['data_hex']
            length = chunk['length']

            total_bytes += length

            f.write(f"--- Chunk {chunk_num} ---\n")
            f.write(f"å­—èŠ‚é•¿åº¦: {length}\n")

            # ä» hex æ¢å¤å­—èŠ‚
            try:
                chunk_bytes = bytes.fromhex(data_hex)
                chunk_str = chunk_bytes.decode('utf-8')

                f.write(f"è§£ç æˆåŠŸ: {len(chunk_str)} å­—ç¬¦\n")

                # å°è¯•è§£æ JSON
                try:
                    data = json.loads(chunk_str, strict=False)
                    f.write("âœ… JSON è§£ææˆåŠŸ\n")

                    # é€’å½’æå–æ‰€æœ‰å†…å®¹
                    def extract_content(obj):
                        contents = []
                        if isinstance(obj, list):
                            for item in obj:
                                # æ£€æŸ¥ [[...], "model"] æ¨¡å¼
                                if isinstance(item, list) and len(item) >= 2 and item[1] == "model":
                                    payload_list = item[0]
                                    for payload in payload_list:
                                        if isinstance(payload, list) and len(payload) >= 2:
                                            content = payload[1]
                                            if content and isinstance(content, str):
                                                contents.append(content)
                                # é€’å½’
                                contents.extend(extract_content(item))
                        return contents

                    contents = extract_content(data)

                    if contents:
                        f.write(f"æå–åˆ° {len(contents)} ä¸ªå†…å®¹å—:\n")
                        for idx, content in enumerate(contents):
                            f.write(f"\n  å†…å®¹å— {idx+1}:\n")
                            f.write(f"  é•¿åº¦: {len(content)} å­—ç¬¦\n")
                            f.write(f"  é¢„è§ˆ: {content[:100]}...\n")

                            total_content_chars += len(content)
                            all_contents.append(content)
                    else:
                        f.write("âš ï¸  æœªæå–åˆ°å†…å®¹\n")

                except json.JSONDecodeError as e:
                    f.write(f"âŒ JSON è§£æå¤±è´¥: {e}\n")
                    f.write(f"åŸå§‹æ•°æ®å‰ 200 å­—ç¬¦: {chunk_str[:200]}\n")

            except Exception as e:
                f.write(f"âŒ å¤„ç†å¤±è´¥: {e}\n")

            f.write("\n")

        # å†™å…¥æ€»ç»“
        f.write("=" * 80 + "\n")
        f.write("ğŸ“Š åˆ†ææ€»ç»“\n")
        f.write("=" * 80 + "\n")
        f.write(f"æ€» Chunk æ•°: {len(chunks)}\n")
        f.write(f"æ€»å­—èŠ‚æ•°: {total_bytes}\n")
        f.write(f"æ€»å†…å®¹å­—ç¬¦æ•°: {total_content_chars}\n")
        f.write(f"æå–çš„å†…å®¹å—æ•°: {len(all_contents)}\n")

    print(f"âœ… è¯¦ç»†åˆ†æå·²ä¿å­˜åˆ°: {output_file}")
    print()

    # æ§åˆ¶å°æ˜¾ç¤ºæ‘˜è¦
    print("ğŸ“Š æ•°æ®æ‘˜è¦:")
    print("-" * 80)
    for idx, content in enumerate(all_contents):
        print(f"  å†…å®¹å— {idx+1}: {len(content)} å­—ç¬¦")
        print(f"    {content[:80]}...")
    print("-" * 80)
    print(f"ğŸ“ˆ æ€»è®¡: {len(chunks)} ä¸ª chunk, {total_bytes} å­—èŠ‚, {total_content_chars} å­—ç¬¦å†…å®¹")
    print()


if __name__ == '__main__':
    print()
    print("ğŸš€ å¯åŠ¨ Gemini åŸå§‹å“åº”å®Œæ•´åˆ†æå·¥å…·")
    print()

    analyze_raw_chunks()

    print()
    print("=" * 80)
    print("âœ… åˆ†æå®Œæˆ")
    print("=" * 80)
    print()
